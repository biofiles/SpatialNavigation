{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cueva & Wei reproduction\n",
    "\n",
    "In this notebook we will try to reproduce the results of Cueva and Wei's 2018 paper \"Emergence of grid-like representations by training recurrent neural networks to perform spatial localization\" [arXiv:1803.07770](https://arxiv.org/abs/1803.07770). This paper will be cited along the notebook to guide the code, since this is a reconstruction.\n",
    "\n",
    "This will be done with a continuous-time RNN as described in the paper.\n",
    "\n",
    "This effort comprises the initial steps of a theoretical neuroscience project involving neural behaviour regarding spatial localization.\n",
    "\n",
    "For questions or suggestions please contact kkohn@itba.edu.ar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages\n",
    "\n",
    "We use numpy and the CTRNN package https://github.com/madvn/CTRNN \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from CTRNN import CTRNN   #Continuous time Recurrent Neural Network package (pip install CTRNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Description\n",
    "Our network model consists of a set of recurrently connected units (N = 100). The dynamics of\n",
    "each unit in the network ui(t) is governed by the standard continuous-time RNN equation:\n",
    "\n",
    " $$ τ\\frac{dxi(t)}{dt} = −x_i(t) + \\sum_{j=1}^N W^{rec}_{ij} u_j(t)\n",
    " + \\sum_{k=1}^N W^{in}_{ik} I_k(t) + b_i + ξ_i(t) \\tag{1}$$ for i = 1, . . . , N. \n",
    "\n",
    "The activity of each unit, $u_i(t)$, is related to the activation of that unit, $x_i(t)$,\n",
    "through a nonlinearity which in this study we take to be $u_i(t) = tanh(x_i(t))$. Each unit receives\n",
    "input from other units through the recurrent weight matrix $W_{rec}$ and also receives external input,\n",
    "I(t), that enters the network through the weight matrix $W_{in}$. Each unit has two sources of bias,\n",
    "$b_i$ which is learned and $ξ_i(t)$ which represents noise intrinsic to the network and is taken to be\n",
    "Gaussian with zero mean and constant variance. The network was simulated using the Euler method\n",
    "for T = 500 timesteps of duration τ /10.\n",
    "\n",
    "To perform a 2D navigation task with the RNN, we linearly combine the firing rates of units in\n",
    "the network to estimate the current location of the animal. The responses of the two linear readout\n",
    "neurons, $y_1(t)$ and $y_2(t)$, are given by the following equation:\n",
    "$$y_j (t) = \\sum^N_{i=1} W_{ji}^{out} u_i(t) \\tag{2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "N = 100 # no. of units\n",
    "T = 500 # no. of timesteps\n",
    "step_size = T/100\n",
    "zi = np.random.randn()\n",
    "\n",
    "#network set up\n",
    "network = CTRNN(size=N,step_size=step_size)\n",
    "network.taus = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input to the network\n",
    "The network inputs and outputs were inspired by simple spatial navigation tasks in 2D open environments. The task resembles dead-reckoning (sometimes referred to as path integration), which is\n",
    "ethologically relevant for many animal species (Darwin, 1873; Mittelstaedt & Mittelstaedt, 1980;\n",
    "Etienne & Jeffery, 2004; McNaughton et al., 2006). To be more specific, the inputs to the network\n",
    "were the animal’s speed and direction at each time step. Experimentally, it has been shown that the\n",
    "velocity signals exist in EC (Sargolini et al., 2006; Kropff et al., 2015; Hinman et al., 2016), and\n",
    "there is also evidence that such signals are necessary for grid formation (Winter et al., 2015a;b).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "We optimized the network parameters Wrec, Win, b and Wout to minimize the squared error in equation (3) between target x- and y-coordinates from a two dimensional navigation task (performed in rectangular, hexagonal, and triangular arenas) and the network outputs generated according to equation (2).\n",
    "\n",
    "$$ E = \\frac{1}{MT N_{out}}\\sum^{M,T,N_{out}}_{m,t,j=1}\n",
    "(y_j (t, m) − y^{target}_j(t, m))^2\\tag{3}$$\n",
    "\n",
    "Parameters were updated with the *Hessian-free algorithm* (Martens & Sutskever, 2011) using minibatches of size M = 500 trials. In addition to minimizing the error function in equation (3) we regularized the input and output weights according to equation (4) and the squared firing rates of the units (referred to as metabolic cost) according to equation (5). In sum, the training aims to minimize a loss function, that consists of the error of the animal, the metabolic cost, and a penalty for large network parameters.\n",
    "\n",
    "$$R_{L2} = \\frac{1}{NN_{in}}\\sum^{N,N_{in}}_{i,j=1}\n",
    "(W^{in}_{ij})^2 +\\frac{1}{NN_{out}}\\sum^{N,N_{out}}_{i,j=1}\n",
    "(W^{out}_{ij})^2 \\tag{4}$$\n",
    "\n",
    "$$R_{FR} = \\frac{1}{NTM}\\sum^{N,T,M}_{i,t,m=1}\n",
    "u_i(t, m)^2 \\tag{5}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
